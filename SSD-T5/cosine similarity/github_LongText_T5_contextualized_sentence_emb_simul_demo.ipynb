{"cells":[{"cell_type":"markdown","metadata":{"id":"LjdBy2RTnzSz"},"source":["# Prep dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":34592,"status":"ok","timestamp":1669831224535,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"zr7TJOrdn1CP","outputId":"31a05e91-6250-486e-cf38-040fa62c2a10"},"outputs":[],"source":["import pandas as pd # data wrangling\n","import numpy as np # math and data analytics\n","import os\n","import scipy\n","import scipy.stats\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","data_foloder = 'here'\n","result = 'here'\n","\n","baseline = pd.read_csv(data_foloder + 'here.csv')\n","incoh10 = pd.read_csv(data_foloder + 'here.csv')\n","incoh20 = pd.read_csv(data_foloder + 'here.csv')\n","incoh50 = pd.read_csv(data_foloder + 'here.csv')\n","ineff10 = pd.read_csv(data_foloder + 'here.csv')\n","ineff20 = pd.read_csv(data_foloder + 'here.csv')\n","ineff50 = pd.read_csv(data_foloder + 'here.csv')\n","\n","baseline.head()"]},{"cell_type":"markdown","metadata":{"id":"FxU_ad_qWNDz"},"source":["# Install lib and dependencies"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":80724,"status":"ok","timestamp":1669831365697,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"NaepnjbLPmUY","outputId":"eb8d39a8-f853-4614-a5b8-6f6ea4649bb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_text\n","  Downloading tensorflow_text-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 34.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n","Collecting tensorflow<2.12,>=2.11.0\n","  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[K     |████████████████████████████████| 588.3 MB 6.2 kB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.1.1)\n","Collecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n","\u001b[K     |████████████████████████████████| 6.0 MB 59.4 MB/s \n","\u001b[?25hCollecting keras<2.12,>=2.11.0\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 52.5 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (57.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (21.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (14.0.6)\n","Collecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[K     |████████████████████████████████| 439 kB 70.4 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.50.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.14.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.23.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.2.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.10.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.9)\n","Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.2\n","    Uninstalling tensorflow-2.9.2:\n","      Successfully uninstalled tensorflow-2.9.2\n","Successfully installed flatbuffers-22.11.23 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"]}],"source":["# Install T5 sentence encoders from TensorFlow Hub\n","# https://tfhub.dev/google/sentence-t5/st5-large/1\n","# Sentence encoders for English built on top of T5 models.\n","\n","# Use colab because M1 keeps having issues with tf [version incompatible?]; \n","# faster with TPU; all deidentified; don't need API key\n","\n","!pip install tensorflow_text"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28572,"status":"ok","timestamp":1669831394260,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"zArzKVGVPs3s","outputId":"9c5d597f-7307-4c06-e111-167642b3af5b"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n","WARNING:absl:Importing a function (__inference_<lambda>_9720) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_<lambda>_3354) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n","WARNING:absl:Importing a function (__inference_<lambda>_6722) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"]},{"name":"stdout","output_type":"stream","text":["[<tf.Tensor: shape=(3, 768), dtype=float32, numpy=\n","array([[-0.02498951, -0.01846411,  0.01713568, ..., -0.03794743,\n","        -0.06852311,  0.00769102],\n","       [-0.01642575, -0.01902249,  0.01045546, ..., -0.00347666,\n","        -0.0248219 , -0.02178053],\n","       [-0.01585932, -0.00118521,  0.01167279, ...,  0.02128684,\n","        -0.03940554,  0.01317421]], dtype=float32)>]\n"]}],"source":["# encode sentences using tensorflow\n","\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","import tensorflow_text as text  # Registers the ops.\n","\n","english_sentences = tf.constant([\"dog\", \"Puppies are nice.\", \"I enjoy taking long walks along the beach with my dog.\"])\n","\n","hub_url = \"https://tfhub.dev/google/sentence-t5/st5-base/1\" # the largest model we can do using cpu\n","encoder = hub.KerasLayer(hub_url)\n","\n","english_embeds = encoder(english_sentences)\n","\n","print (english_embeds) # 3 phrases; 768 dimension"]},{"cell_type":"markdown","metadata":{"id":"-BPGDO0CUsbZ"},"source":["# Get contextualized sentence embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":113959,"status":"ok","timestamp":1669831521842,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"A6alcqyYUvzR","outputId":"fb0436b3-14d8-4677-b1a7-70bad9322b3e"},"outputs":[],"source":["# define a function\n","# get contextualized sentence embeddings\n","# using t5 sentence encoder\n","def get_sent_emb(s):\n","  result = encoder(s)[0].numpy()\n","  return result\n","\n","dfs = [baseline, incoh10, incoh20, incoh50, ineff10, ineff20, ineff50]\n","temp = -1\n","for df in dfs:\n","  temp += 1\n","  df[\"t5_sent_emb\"] = ''\n","  # apply the embedding function to the data frame\n","  df[\"t5_sent_emb\"] = df['content'].apply(lambda x: get_sent_emb(x.split('.'))) \n","  df.to_csv(result + str(temp) + '_sent.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":616,"status":"ok","timestamp":1669741350537,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"FWKtf-PZVoXE","outputId":"59818586-eaf2-46db-cad3-b76c9bffcc5b"},"outputs":[{"data":{"text/plain":["14"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["len(baseline['content'][0].split('.')) # number of sentences in the response"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669741274114,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"x-1QVsIxVJLe","outputId":"615303e4-e32a-4504-e408-59b9ec4838bb"},"outputs":[{"data":{"text/plain":["14"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(baseline['t5_sent_emb'][0]) # number of sentence emb in the response vector"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1669741294697,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"ImaHBX_qViHl","outputId":"678c5168-21dc-4f50-ae1d-fc366371b9fc"},"outputs":[{"data":{"text/plain":["768"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["len(baseline['t5_sent_emb'][0][0]) # each sentence vector is 768 dimension"]},{"cell_type":"markdown","metadata":{"id":"6aSHuMgcp6A8"},"source":["# Stats and similarities functions"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":498,"status":"ok","timestamp":1669831741589,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"7C5szWuUp8Az"},"outputs":[],"source":["# stats ignoring nan, apply to all LMs \n","from numpy import nanmedian\n","\n","import scipy\n","def iqr(x):\n","  return scipy.stats.iqr(np.array(x), nan_policy='omit')\n","\n","from numpy import nanquantile\n","def q5(x):\n","    return np.nanquantile(np.array(x), 0.05)\n","\n","def q95(x):\n","    return np.nanquantile(np.array(x), 0.95)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":362,"status":"ok","timestamp":1669831534527,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"v_XUJLqKp9ts"},"outputs":[],"source":["# cosine_similarity, apply to all LMs\n","def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"]},{"cell_type":"markdown","metadata":{"id":"0npkY_DfXJu3"},"source":["# FOC and SOC"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1669831542182,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"lE0x90kyqYSM","outputId":"314f104b-d43c-4ad7-b534-266f38bfe26e"},"outputs":[],"source":["cs=['foc', 'soc']\n","stats = ['_median', '_iqr', '_q5', '_q95']\n","for df in dfs:\n","    # create new empty columns\n","    for c in cs:\n","        for stat in stats:\n","            cur = 't5_' + c + stat\n","            df[cur] = ''\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4733,"status":"ok","timestamp":1669831752179,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"2SGSqz2eqmky","outputId":"d6a0a81c-aa63-43f9-a37c-a7187be471bb"},"outputs":[],"source":["temp_file = -1 # keep track of file names\n","for df in dfs:\n","    temp_file += 1\n","    df['t5_foc_similarity'] = ''\n","    df['t5_soc_similarity'] = ''\n","    # loop over each response\n","    for i in df.index:\n","        temp_foc = [] # for each individual, store the list of cos similarity\n","        temp_soc = []\n","        # calculate average similarity for sentence pairs, either adjacent or with one intervening\n","        for idx, sent in enumerate(df['t5_sent_emb'][i]):\n","            try:\n","                temp_foc.append(cosine_similarity(sent, df['t5_sent_emb'][i][idx+1])) # get a list of similarities for that response\n","                \n","                df['t5_foc_similarity'][i] = temp_foc # record intermediate similarities \n","                \n","                df['t5_foc_median'][i] = np.nanmedian(temp_foc) # add more stats here\n","                df['t5_foc_iqr'][i] = iqr(temp_foc)\n","                df['t5_foc_q5'][i] = q5(temp_foc)\n","                df['t5_foc_q95'][i] = q95(temp_foc)\n","\n","                temp_soc.append(cosine_similarity(sent, df['t5_sent_emb'][i][idx+2]))\n","\n","                df['t5_soc_similarity'][i] = temp_soc # record intermediate similarities \n","\n","                df['t5_soc_median'][i] = np.nanmedian(temp_soc)\n","                df['t5_soc_iqr'][i] = iqr(temp_soc)\n","                df['t5_soc_q5'][i] = q5(temp_soc)\n","                df['t5_soc_q95'][i] = q95(temp_soc)\n","\n","            except IndexError:\n","                continue\n","    df.to_csv(result + str(temp_file) + '_sent.csv')\n","df.head()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
