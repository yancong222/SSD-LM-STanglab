{"cells":[{"cell_type":"markdown","metadata":{},"source":["# note: This program needs openAI API"]},{"cell_type":"markdown","metadata":{"id":"MXUX3Z1dJOcw"},"source":["# Prep dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZuHPbrbAJOcy"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import scipy\n","import re\n","\n","os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_foloder = 'your folder'\n","\n","baseline = pd.read_csv(data_foloder + 'test.csv')\n","\n","baseline.head() "]},{"cell_type":"markdown","metadata":{},"source":["# Install lib and dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rmelhcu1JOc2","outputId":"31e9eed6-24ab-4a28-d4a2-0607f26f899e"},"outputs":[],"source":["!pip install transformers # no need to install every time you open it"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"jf7X4aosJOc2"},"outputs":[],"source":["import transformers\n","from transformers import GPT2TokenizerFast\n","tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"-biYC5D0JOc5"},"outputs":[],"source":["from openai.embeddings_utils import get_embeddings, cosine_similarity # important\n","import openai\n","openai.api_key = 'your key'"]},{"cell_type":"markdown","metadata":{},"source":["# Get sent embeddings from GPT3 response embeddings 3df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["buglist = {}\n","def calc_gpt3(r):  # get embeddings\n","  if r[0] % 2 != 0: # progress: print even grid\n","    print('current grid: ', r[0])\n","  if type(r['content']) == str and r['n_words'] < 2048: # max for GPT3\n","    temp = r['content'].split(' ') \n","    input = ' '.join([i for i in temp if (i != '') & ('{' not in i) & ('}' not in i) & ('#' not in i)]) # triple check: exclude NSV and the restart symbol\n","    try:\n","      # split by . or ? or !\n","      input.replace('?', '.').replace('!', '.')\n","      vec = get_embeddings(input.split(' . '), engine = 'your engine') # take in the whose response as a list of sentence, sep by . ! ?\n","    except:\n","      buglist[r[0]] = input.split(' ') # store grid\n","    return vec\n","  else:\n","    return np.nan\n","\n","# double check your input df\n","# make sure there is no '  ' or '   '\n","\n","dfs = [baseline]\n","temp = -1\n","for df in dfs:\n","  temp += 1\n","  df = df[df['grid'] == 'test000'] # only select 1 individual for demo purpose\n","  df[\"gpt3_embed\"] = '' # create a new empty column\n","  df[\"gpt3_embed\"] = df.apply(lambda r: calc_gpt3(r), axis = 1) # apply the embedding function to the dataframe\n","  df.to_csv(str(temp) + '_sent.csv') \n","df.head()"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["{}"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["buglist"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["13"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["len(df['gpt3_embed'][1]) # the number of sentences in that response"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["2048"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["len(df['gpt3_embed'][1][3]) # every sentence get a len (i.e. dimension) 2048 embedding vector"]},{"cell_type":"markdown","metadata":{},"source":["# FOC and SOC"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# stats ignoring nan\n","from numpy import nanmedian\n","\n","import scipy\n","def iqr(x):\n","  return scipy.stats.iqr(np.array(x), nan_policy='omit')\n","\n","from numpy import quantile\n","def q5(x):\n","    return np.quantile(np.array(x), 0.05)\n","\n","def q95(x):\n","    return np.quantile(np.array(x), 0.95)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["temp_file = 0 # give df a temp name; the intermediate df will be discarded bcs otherwise it occupies too much space\n","cs=['foc', 'soc']\n","stats = ['_median', '_iqr', '_q5', '_q95']\n","dfs = [df]\n","for df in dfs:\n","    temp += 1\n","    # create new empty columns\n","    for c in cs:\n","        for stat in stats:\n","            cur = 'gpt3_' + c + stat\n","            df[cur] = ''\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["temp_file = -1 # keep track of file names\n","for df in dfs:\n","    temp_file += 1\n","    df['gpt3_foc_similarity'] = ''\n","    df['gpt3_soc_similarity'] = ''\n","    # loop over each response\n","    for i in df.index:\n","        temp_foc = [] # for each individual, store the list of cos similarity\n","        temp_soc = []\n","        # calculate average similarity for sentence pairs, either adjacent or with one intervening\n","        for idx, sent in enumerate(df['gpt3_embed'][i]):\n","            try:\n","                temp_foc.append(cosine_similarity(sent, df['gpt3_embed'][i][idx+1])) # get a list of similarities for that response\n","                \n","                df['gpt3_foc_similarity'][i] = temp_foc # record intermediate similarities \n","                \n","                df['gpt3_foc_median'][i] = np.nanmedian(temp_foc) # add more stats here\n","                df['gpt3_foc_iqr'][i] = iqr(temp_foc)\n","                df['gpt3_foc_q5'][i] = q5(temp_foc)\n","                df['gpt3_foc_q95'][i] = q95(temp_foc)\n","\n","                temp_soc.append(cosine_similarity(sent, df['gpt3_embed'][i][idx+2]))\n","\n","                df['gpt3_soc_similarity'][i] = temp_soc # record intermediate similarities \n","\n","                df['gpt3_soc_median'][i] = np.nanmedian(temp_soc)\n","                df['gpt3_soc_iqr'][i] = iqr(temp_soc)\n","                df['gpt3_soc_q5'][i] = q5(temp_soc)\n","                df['gpt3_soc_q95'][i] = q95(temp_soc)\n","\n","            except IndexError:\n","                continue\n","    df.to_csv(str(temp_file) + '_sent.csv')\n","df.head()"]}],"metadata":{"colab":{"name":"gpt3_wordEmbd_foc_soc.ipynb","provenance":[],"toc_visible":true},"interpreter":{"hash":"c9bbc2a1c928760b171406dd0b75aa2bc786a11b1c33c4ac331981aff1f6a975"},"kernelspec":{"display_name":"Python 3.9.7 ('nlum1')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
