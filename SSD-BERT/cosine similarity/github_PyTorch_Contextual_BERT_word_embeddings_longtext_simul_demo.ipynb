{"cells":[{"cell_type":"markdown","metadata":{"id":"zsGkU-Sq7gms"},"source":["# Prep dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":1472,"status":"ok","timestamp":1669836289261,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"nuJ6_wGp7gQD","outputId":"d7d37f72-9820-4f4b-bcc3-61da7d540fc3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import scipy\n","import scipy.stats\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","data_foloder = '/here'\n","result = 'here'\n","\n","baseline = pd.read_csv(data_foloder + 'here.csv')\n","incoh10 = pd.read_csv(data_foloder + 'here.csv')\n","incoh20 = pd.read_csv(data_foloder + 'here.csv')\n","incoh50 = pd.read_csv(data_foloder + 'here.csv')\n","ineff10 = pd.read_csv(data_foloder + 'here.csv')\n","ineff20 = pd.read_csv(data_foloder + 'here.csv')\n","ineff50 = pd.read_csv(data_foloder + 'here.csv')\n","\n","baseline.head()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1669835534305,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"2CHgD_9b71Hv","outputId":"bd66a9b8-d3c5-47da-800e-aee30492ad57"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["os.getcwd()"]},{"cell_type":"markdown","metadata":{"id":"_Dj2Q0K68HAh"},"source":["# Install lib and dependencies"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":523,"status":"ok","timestamp":1669836229598,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"aGi5cAL88Vaa"},"outputs":[],"source":["# Install the transformers package from Hugging Face \n","# which will give us a pytorch interface for working with BERT.\n","\n","import torch\n","from collections import OrderedDict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KysF7CSR_r9P"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":161,"status":"ok","timestamp":1669835551936,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"PFsyNaSJ8c2-","outputId":"a36bad48-47b1-43fe-bf96-11123252147f"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# check if any GPU instance is availabe\n","# https://www.databricks.com/blog/2021/10/28/gpu-accelerated-sentiment-analysis-using-pytorch-and-huggingface-on-databricks.html\n","# 'cude': GPU\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n","DEVICE"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219,"referenced_widgets":["e890c465960d421a8055a147cbac69e9","6ecbddb35d994a5897f5dc2fb77c890e","67176fb7130c4979852468ad8236eac1","892a9f8089ab4353982bcab4d1b3f163","ceab9c8497cb45918beb314d06a65b52","6258ed8a67d343c69b8ca7508703eec6","af782eb560f14302867d306c53c7db08","183d6d199cc44f468d089c903f9f580d","a2b65a4532024d8ba1402bad9d84b26c","bddb86435cd64a818e1d13feb0067829","49022a0896b544639c3381f426f6ecc0","e6cfc37c4b83414a85d16b66b6e22c76","bd9a9b81f5764714971c75b1ed488952","c0e49fefe86049cab5698cafaf4c2c5f","81f232c9fa8e43bdb0c427a1dec99690","cf39e009b6904c91b34a815dfc17ac31","7c5819534bb5431eb5fcde93a587bf70","f56ac4c077e247968d26019137c9b312","16d092fbdec14ed78bc6060fe7e6ed2a","efe4b861a2fb4b6d9bb1cd3c711227cc","a53ca192f96b490b95ee8f411e7256e7","5716f3f59d7742769cc3d429aa8456c0","bd0c334f1f174722a85a62ea13025ac1","0aadc949f7574adfad5a22ae49e31c57","ed5a4337e1154020a9d2201da1b47b0b","0bfb6a345b914b8098a8c4039d4e5b6d","aa5c749e4a724a8d840684659a4854a4","f3fa3f1462c740eaa26389fedcad9cd5","e697e7e413be4cb1b3f655d0917d07cf","9bf90828dddd44118b87f968159f9389","3105652673c2446abaad8c4fb4cead21","267a397bb80146cdb861eec5e42311aa","70dc19de9a40414896c737fe3184f734","d2f4578bf8b54eac8cf37b0c386d315d","2e17f5ec84d84151975fc6d334cdec6c","d7e6ae8a128c459ca3225aae315c6fea","a7a5d8ea90f9406f8ae8e937af54d463","d1a0c6de1c4a4aecaeca766fa305c358","76c6b363d64048b6bb6da414a3771435","edeea8866f924c478ca17381f8701963","5b20ffe6a9884261b9f61b7d66b4f666","14a6b54ef7ec4cf39284b1ca32904559","e09607f7dab1452d8dfd2df875ef086e","73189376225b4208a9d888bffd273df8"]},"executionInfo":{"elapsed":32794,"status":"ok","timestamp":1669835587363,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"S-AMLSmc8i3W","outputId":"8f9432c6-ca1a-4a61-c629-d20eef5aa72a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e890c465960d421a8055a147cbac69e9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6cfc37c4b83414a85d16b66b6e22c76","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd0c334f1f174722a85a62ea13025ac1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2f4578bf8b54eac8cf37b0c386d315d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# load the pre-trained BERT model and tokenizer\n","from transformers import BertModel, BertTokenizer\n","\n","model = BertModel.from_pretrained('bert-base-uncased', # for both word level and utterance level\n","           output_hidden_states = True) #.to(DEVICE); the above cell already takes care of this\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"markdown","metadata":{"id":"FpwY5g4NK07V"},"source":["# Contextualized word embeddings"]},{"cell_type":"markdown","metadata":{"id":"FoNmLo5D5rBk"},"source":["Put the input text into a specific format that BERT can read. add the ```[CLS]``` to the beginning and ```[SEP]``` to the end of the input. convert the tokenized BERT input to the tensor format."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1669835625644,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"l5GKOZx7Xo4M"},"outputs":[],"source":["def bert_text_preparation(text, tokenizer):\n","  \"\"\"\n","  Preprocesses text input in a way that BERT can interpret.\n","  \"\"\"\n","  marked_text = \"[CLS] \" + text + \" [SEP]\" # add special tokens\n","  tokenized_text = tokenizer.tokenize(marked_text)\n","  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text) # find token IDs\n","  segments_ids = [1]*len(indexed_tokens) # for formating and vectors matrix calculations [not really an ID]\n","\n","  # convert inputs to tensors\n","  tokens_tensor = torch.tensor([indexed_tokens])\n","  segments_tensor = torch.tensor([segments_ids])\n","\n","  return tokenized_text, tokens_tensor, segments_tensor"]},{"cell_type":"markdown","metadata":{"id":"FXfARxCaQL0B"},"source":["to obtain the actual BERT embeddings, we take preprocessed input text, which now is represented by tensors, put it into our pre-trained BERT model.\n","\n","which vector works best as a contextualized embedding depends on the task. \n","\n","according to Devlin et al (2019), the sum of the last four layers of the model worked well for NLP tasks"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":155,"status":"ok","timestamp":1669835627992,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"pqYxJi28X63W"},"outputs":[],"source":["def get_bert_embeddings(tokens_tensor, segments_tensor, model):\n","    \"\"\"\n","    Obtains BERT embeddings for tokens, in context of the given response.\n","    \"\"\"\n","    # gradient calculation id disabled\n","    with torch.no_grad():\n","      # obtain hidden states\n","      outputs = model(tokens_tensor, segments_tensor)\n","      hidden_states = outputs[2]\n","\n","    # concatenate the tensors for all layers\n","    # use \"stack\" to create new dimension in tensor\n","    token_embeddings = torch.stack(hidden_states, dim=0)\n","\n","    # remove dimension 1, the \"batches\"\n","    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n","\n","    # swap dimensions 0 and 1 so we can loop over tokens \n","    token_embeddings = token_embeddings.permute(1,0,2)\n","\n","    # intialized list to store embeddings\n","    token_vecs_sum = []\n","\n","    # \"token_embeddings\" is a [Y x 12 x 768] tensor\n","    # where Y is the number of tokens in the response\n","\n","    # loop over tokens in response\n","    for token in token_embeddings:\n","\n","        # \"token\" is a [12 x 768] tensor\n","\n","        # sum the vectors from the last four layers\n","        sum_vec = torch.sum(token[-4:], dim=0)\n","        token_vecs_sum.append(sum_vec)\n","\n","    return token_vecs_sum"]},{"cell_type":"markdown","metadata":{"id":"7coBP8FjQ_Is"},"source":["create contextual embeddings for a response."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669836300119,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"WJii4Mev9swB","outputId":"fd402b8c-ff90-4279-f16a-19f1f9aedd35"},"outputs":[],"source":["# call the function \n","# apply it to the dataframe\n","dfs = [baseline, incoh10, incoh20, incoh50, ineff10, ineff20, ineff50]\n","temp = -1\n","for df in dfs:\n","  temp += 1\n","  df[\"bert_emb\"] = ''\n","  df.to_csv(result + str(temp) + '.csv')\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":167128,"status":"ok","timestamp":1669836764162,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"Mb_UeXhH_CQe","outputId":"b36bef7b-0c60-4dc6-ccf8-9f8ea3f2d96e"},"outputs":[],"source":["for df in dfs: \n","  for i in df.index:\n","    context_embeddings = []\n","    if df['n_words'][i] > 4: # only process lines with response len bigger than 4\n","        # only keep the first 430 tokens. BERT uses a subword tokenizer (WordPiece), \n","        # so the maximum length corresponds to 512 subword tokens.\n","        lst = df['content'][i].split(' ')[:431] \n","        sentence = ' '.join(lst)\n","        tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(sentence, tokenizer)\n","        list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n","\n","        # make ordered dictionary to keep track of the position of each word\n","        tokens = OrderedDict()\n","\n","        # loop over tokens in sensitive sentence\n","        for token in tokenized_text[1:-1]:\n","          # keep track of position of word and whether it occurs multiple times\n","          if token in tokens:\n","            tokens[token] += 1\n","          else:\n","            tokens[token] = 1\n","\n","          # compute the position of the current token\n","          token_indices = [i for i, t in enumerate(tokenized_text) if t == token]\n","          current_index = token_indices[tokens[token]-1]\n","\n","          # get the corresponding embedding\n","          token_vec = list_token_embeddings[current_index]\n","          \n","          # save values\n","          context_embeddings.append(token_vec)\n","\n","        df['bert_emb'][i] = context_embeddings\n","\n","    if i % 5 == 0:\n","        print('progress: ', i)\n","\n","  df.to_csv(result + str(temp) + '.csv')  \n","  \n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"pg8Csj6sBgF1"},"source":["# Stats and similarities functions"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":158,"status":"ok","timestamp":1669836811524,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"AIJGErDaBiom"},"outputs":[],"source":["# stats ignoring nan, apply to all LMs \n","from numpy import nanmedian\n","\n","import scipy\n","def iqr(x):\n","  return scipy.stats.iqr(np.array(x), nan_policy='omit')\n","\n","from numpy import nanquantile\n","def q5(x):\n","    return np.nanquantile(np.array(x), 0.05)\n","\n","def q95(x):\n","    return np.nanquantile(np.array(x), 0.95)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1669836812083,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"5HzFsKl8BlDi"},"outputs":[],"source":["# cosine_similarity, apply to all LMs\n","def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"]},{"cell_type":"markdown","metadata":{"id":"EXYvB2KkBeIl"},"source":["# MV5/10"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1669836814610,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"i969ISRtBfP7","outputId":"3b8eaefd-b548-452e-dc90-d0d1cbc0eeda"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['Alex', 'broke', 'the', 'vase', 'accidentally'], ['.', 'But', 'Kai', 'did', 'it'], ['on', 'purpose', '.']]\n"]}],"source":["# Average semantic similarity of each word in 5- or 10- words window\n","\n","def divide_chunks(l, n):\n","    # looping till length l\n","    for i in range(0, len(l), n): \n","        yield l[i:i + n]\n","  \n","# n: How many elements each\n","# list should have\n","test = ['Alex','broke','the','vase','accidentally','.','But','Kai','did','it','on','purpose','.']\n","divide_chunks(test,5)\n","chopped = list(divide_chunks(test,5))\n","print(chopped)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1669836819061,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"zxx7yiFhBrEb","outputId":"21fc7b9f-dbc1-4dac-e0fe-c73ae99e042f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['Alex', 'broke'], ['Alex', 'the'], ['Alex', 'vase'], ['Alex', 'accidentally'], ['broke', 'the'], ['broke', 'vase'], ['broke', 'accidentally'], ['the', 'vase'], ['the', 'accidentally'], ['vase', 'accidentally']]\n"]}],"source":["def combinations(lst): # get w1, w2 combinations\n","    # input: a list of <= 5 tokens\n","    cmb = []\n","    rightside = lst[:] # initialize a list\n","    for wid, w1 in enumerate(lst): # each token gets a chance to be w1\n","        rightside = lst[wid:] # dynamically chop off w1 from the rest of the list\n","        while rightside: # loop until the rest of the list is empty\n","            w2 = rightside.pop(0) # stack up w2\n","            if w2 != w1: # get rid of ['Alex', 'Alex']\n","                cmb.append([w1, w2])  \n","    return cmb\n","\n","testing = ['Alex', 'broke', 'the', 'vase', 'accidentally']\n","test_result = combinations(testing)\n","print(test_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"executionInfo":{"elapsed":17743,"status":"ok","timestamp":1669836844012,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"RrXGzprABtKT","outputId":"d83eb786-add5-4e49-999c-d62bc271a7ec"},"outputs":[],"source":["# prep dataframe\n","# append columns to the embeddings df\n","\n","mvs=['5', '10']\n","stats = ['_median', '_iqr', '_q5', '_q95'] \n","for df in dfs:\n","    # create new empty columns\n","    for mv in mvs:\n","        for stat in stats:\n","            cur = 'bert_word_mv' + mv + stat\n","            df[cur] = ''\n","df.head()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1669836972765,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"WlSX8A2KChDq","outputId":"8a35ce2b-73ee-4ccd-8001-92746361f23d"},"outputs":[{"data":{"text/plain":["431"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["len(df['bert_emb'][0]) # it's a list of 431 tensor"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160,"status":"ok","timestamp":1669837549799,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"jdVe0fRBCi9z","outputId":"0ee01a33-cf0f-4d72-bd01-776b0b2c0ee8"},"outputs":[{"data":{"text/plain":["torch.Size([768])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df['bert_emb'][0][1].shape # each tensor is 768 dimension"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":126487,"status":"ok","timestamp":1669838592456,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"lWQB3QuNBw4G","outputId":"eda5c28d-bf50-4fa4-eaf2-e71c7b0f9d01"},"outputs":[],"source":["# combinations 'alex broke the vase': \n","# alex broke, alex the, alex vase; broke the, broke vase; the vase\n","# Parola et al is inspired by Pauselli et al (p76): \n","# ''Coherence is the average similarity of each word to each of the other\n","# words in the list, regardless of order or proximity. ''\n","# w2 = word_embed[word_id+1] # adjacent neighbour only\n","temp_file = -1\n","for df in dfs:\n","    temp_file += 1\n","    print(temp_file)\n","    for mv in mvs:\n","        # print progress\n","        cur = 'bert_word_mv' + mv\n","        print('current: ', cur)\n","        df[cur + '_similarity'] = '' # save the cosine similarities; all stats are derived from there\n","\n","        # loop over each response\n","        for i in df.index:\n","            if type(df['bert_emb'][i]) != float: \n","                # chop 1 big response sequence into 5/10-token chunks\n","                word_embed_chunk = list(divide_chunks(df['bert_emb'][i], int(mv))) \n","                chunk_temp_collection = [] \n","                # loop over each 5/10 chunk in the response\n","                for chunck_id, word_embed in enumerate(word_embed_chunk):\n","                    temp_collection = []\n","                    # add this for BERT to convert a list of tensors to a list of lists\n","                    word_embed = [x.numpy().tolist() for x in word_embed]\n","                    # calculate average similarities for that chunk (5 or 10 window)                   \n","                    cmbs = combinations(word_embed) # apply function \n","                    for cmb in cmbs:\n","                        w1 = cmb[0]\n","                        w2 = cmb[1]\n","                        temp = cosine_similarity(w1, w2)\n","                        temp_collection.append(temp)\n","                    temp_sim = np.nanmean(temp_collection)\n","                    chunk_temp_collection.append(temp_sim) # incrementally append similarity mean to the list \n","\n","            # get a list of similarity means for that response, \n","            # its len is the number of chunks that the response can be chopped into\n","            df[cur + '_similarity'][i] = chunk_temp_collection # similarity mv 5 or 10; store it for later reference/stats\n","\n","            # add other stats here\n","            df[cur + '_median'][i] = np.nanmedian(chunk_temp_collection)\n","            df[cur + '_q5'][i] = q5(chunk_temp_collection)\n","            df[cur + '_q95'][i] = q95(chunk_temp_collection)\n","            df[cur + '_iqr'][i] = iqr(chunk_temp_collection)\n","    df.to_csv(result + str(temp_file) + '.csv')\n","df.head()"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1669838630604,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"rmZ6lsKFIiiJ","outputId":"4c358381-6f82-4fc5-9748-5adc9d6c54a4"},"outputs":[{"data":{"text/plain":["Index(['grid', 'content', 'n_words', 'bert_emb', 'bert_word_mv5_median',\n","       'bert_word_mv5_iqr', 'bert_word_mv5_q5', 'bert_word_mv5_q95',\n","       'bert_word_mv10_median', 'bert_word_mv10_iqr', 'bert_word_mv10_q5',\n","       'bert_word_mv10_q95', 'bert_word_mv5_similarity',\n","       'bert_word_mv10_similarity'],\n","      dtype='object')"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"markdown","metadata":{"id":"P1gHa736d-11"},"source":["# K1:10"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":699},"executionInfo":{"elapsed":18299,"status":"ok","timestamp":1669838886922,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"4knHh45pBan2","outputId":"b1db05e8-445c-414e-a50e-b72884eadc02"},"outputs":[],"source":["import ast # a module that evaluates mathematical expressions and statements\n","\n","ks=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n","stats = ['_median', '_iqr', '_q5', '_q95']\n","for df in dfs:\n","    # create new empty columns\n","    for k in ks:\n","        for stat in stats:\n","            cur = 'bert_word_k' + k + stat\n","            df[cur] = ''\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":106553,"status":"ok","timestamp":1669839121479,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"hOhCXdk7Impu","outputId":"cb75607b-67ca-4ab4-acfe-fa6f926ba272"},"outputs":[],"source":["temp_file = -1\n","ks=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n","\n","for df in dfs:\n","    temp_file += 1\n","    # loop through each k\n","    for k in ks:\n","        cur = 'bert_word_k' + k \n","        print('Coherence k ', k, 'temp_file: ', temp_file) # progress\n","        df[cur + '_similarity'] = ''\n","        # loop through each individual's response \n","        for i in df.index:\n","            if type(df['bert_emb'][i]) != float:\n","                temp = []\n","                # calcuate similarity of word pairs at k inter-token distance\n","                for id,v in enumerate(df['bert_emb'][i]): \n","                    w1 = v\n","                    try:\n","                        w2 = df['bert_emb'][i][id + int(k)] \n","                    except IndexError:\n","                        continue\n","                    sim = cosine_similarity(w1, w2)\n","                    temp.append(sim) # a list of similarity scores for that response\n","\n","                # intermediate df, save \n","                df[cur + '_similarity'][i] = temp\n","                df[cur + '_iqr'][i] = iqr(temp) # add other stats here\n","                df[cur + '_median'][i] = np.nanmedian(temp)\n","                df[cur + '_q5'][i] = q5(temp)\n","                df[cur + '_q95'][i] = q95(temp)\n","    df.to_csv(result + str(temp_file) + '.csv')\n","df.head()"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1669839121479,"user":{"displayName":"parsely k","userId":"05819359985786355687"},"user_tz":300},"id":"sddOTzXjIrpP","outputId":"939f1e95-13e7-46e2-97ef-15ee16dc6f08"},"outputs":[{"data":{"text/plain":["Index(['grid', 'content', 'n_words', 'bert_emb', 'bert_word_mv5_median',\n","       'bert_word_mv5_iqr', 'bert_word_mv5_q5', 'bert_word_mv5_q95',\n","       'bert_word_mv10_median', 'bert_word_mv10_iqr', 'bert_word_mv10_q5',\n","       'bert_word_mv10_q95', 'bert_word_mv5_similarity',\n","       'bert_word_mv10_similarity', 'bert_word_k1_median', 'bert_word_k1_iqr',\n","       'bert_word_k1_q5', 'bert_word_k1_q95', 'bert_word_k2_median',\n","       'bert_word_k2_iqr', 'bert_word_k2_q5', 'bert_word_k2_q95',\n","       'bert_word_k3_median', 'bert_word_k3_iqr', 'bert_word_k3_q5',\n","       'bert_word_k3_q95', 'bert_word_k4_median', 'bert_word_k4_iqr',\n","       'bert_word_k4_q5', 'bert_word_k4_q95', 'bert_word_k5_median',\n","       'bert_word_k5_iqr', 'bert_word_k5_q5', 'bert_word_k5_q95',\n","       'bert_word_k6_median', 'bert_word_k6_iqr', 'bert_word_k6_q5',\n","       'bert_word_k6_q95', 'bert_word_k7_median', 'bert_word_k7_iqr',\n","       'bert_word_k7_q5', 'bert_word_k7_q95', 'bert_word_k8_median',\n","       'bert_word_k8_iqr', 'bert_word_k8_q5', 'bert_word_k8_q95',\n","       'bert_word_k9_median', 'bert_word_k9_iqr', 'bert_word_k9_q5',\n","       'bert_word_k9_q95', 'bert_word_k10_median', 'bert_word_k10_iqr',\n","       'bert_word_k10_q5', 'bert_word_k10_q95', 'bert_word_k1_similarity',\n","       'bert_word_k2_similarity', 'bert_word_k3_similarity',\n","       'bert_word_k4_similarity', 'bert_word_k5_similarity',\n","       'bert_word_k6_similarity', 'bert_word_k7_similarity',\n","       'bert_word_k8_similarity', 'bert_word_k9_similarity',\n","       'bert_word_k10_similarity'],\n","      dtype='object')"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0aadc949f7574adfad5a22ae49e31c57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3fa3f1462c740eaa26389fedcad9cd5","placeholder":"​","style":"IPY_MODEL_e697e7e413be4cb1b3f655d0917d07cf","value":"Downloading: 100%"}},"0bfb6a345b914b8098a8c4039d4e5b6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_267a397bb80146cdb861eec5e42311aa","placeholder":"​","style":"IPY_MODEL_70dc19de9a40414896c737fe3184f734","value":" 232k/232k [00:00&lt;00:00, 915kB/s]"}},"14a6b54ef7ec4cf39284b1ca32904559":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16d092fbdec14ed78bc6060fe7e6ed2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"183d6d199cc44f468d089c903f9f580d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"267a397bb80146cdb861eec5e42311aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e17f5ec84d84151975fc6d334cdec6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76c6b363d64048b6bb6da414a3771435","placeholder":"​","style":"IPY_MODEL_edeea8866f924c478ca17381f8701963","value":"Downloading: 100%"}},"3105652673c2446abaad8c4fb4cead21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49022a0896b544639c3381f426f6ecc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5716f3f59d7742769cc3d429aa8456c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b20ffe6a9884261b9f61b7d66b4f666":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6258ed8a67d343c69b8ca7508703eec6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67176fb7130c4979852468ad8236eac1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_183d6d199cc44f468d089c903f9f580d","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2b65a4532024d8ba1402bad9d84b26c","value":570}},"6ecbddb35d994a5897f5dc2fb77c890e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6258ed8a67d343c69b8ca7508703eec6","placeholder":"​","style":"IPY_MODEL_af782eb560f14302867d306c53c7db08","value":"Downloading: 100%"}},"70dc19de9a40414896c737fe3184f734":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73189376225b4208a9d888bffd273df8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76c6b363d64048b6bb6da414a3771435":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c5819534bb5431eb5fcde93a587bf70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81f232c9fa8e43bdb0c427a1dec99690":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a53ca192f96b490b95ee8f411e7256e7","placeholder":"​","style":"IPY_MODEL_5716f3f59d7742769cc3d429aa8456c0","value":" 440M/440M [00:18&lt;00:00, 25.0MB/s]"}},"892a9f8089ab4353982bcab4d1b3f163":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bddb86435cd64a818e1d13feb0067829","placeholder":"​","style":"IPY_MODEL_49022a0896b544639c3381f426f6ecc0","value":" 570/570 [00:00&lt;00:00, 4.72kB/s]"}},"9bf90828dddd44118b87f968159f9389":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2b65a4532024d8ba1402bad9d84b26c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a53ca192f96b490b95ee8f411e7256e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7a5d8ea90f9406f8ae8e937af54d463":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e09607f7dab1452d8dfd2df875ef086e","placeholder":"​","style":"IPY_MODEL_73189376225b4208a9d888bffd273df8","value":" 28.0/28.0 [00:00&lt;00:00, 881B/s]"}},"aa5c749e4a724a8d840684659a4854a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af782eb560f14302867d306c53c7db08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd0c334f1f174722a85a62ea13025ac1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0aadc949f7574adfad5a22ae49e31c57","IPY_MODEL_ed5a4337e1154020a9d2201da1b47b0b","IPY_MODEL_0bfb6a345b914b8098a8c4039d4e5b6d"],"layout":"IPY_MODEL_aa5c749e4a724a8d840684659a4854a4"}},"bd9a9b81f5764714971c75b1ed488952":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c5819534bb5431eb5fcde93a587bf70","placeholder":"​","style":"IPY_MODEL_f56ac4c077e247968d26019137c9b312","value":"Downloading: 100%"}},"bddb86435cd64a818e1d13feb0067829":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0e49fefe86049cab5698cafaf4c2c5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16d092fbdec14ed78bc6060fe7e6ed2a","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efe4b861a2fb4b6d9bb1cd3c711227cc","value":440473133}},"ceab9c8497cb45918beb314d06a65b52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf39e009b6904c91b34a815dfc17ac31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1a0c6de1c4a4aecaeca766fa305c358":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2f4578bf8b54eac8cf37b0c386d315d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e17f5ec84d84151975fc6d334cdec6c","IPY_MODEL_d7e6ae8a128c459ca3225aae315c6fea","IPY_MODEL_a7a5d8ea90f9406f8ae8e937af54d463"],"layout":"IPY_MODEL_d1a0c6de1c4a4aecaeca766fa305c358"}},"d7e6ae8a128c459ca3225aae315c6fea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b20ffe6a9884261b9f61b7d66b4f666","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14a6b54ef7ec4cf39284b1ca32904559","value":28}},"e09607f7dab1452d8dfd2df875ef086e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e697e7e413be4cb1b3f655d0917d07cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6cfc37c4b83414a85d16b66b6e22c76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd9a9b81f5764714971c75b1ed488952","IPY_MODEL_c0e49fefe86049cab5698cafaf4c2c5f","IPY_MODEL_81f232c9fa8e43bdb0c427a1dec99690"],"layout":"IPY_MODEL_cf39e009b6904c91b34a815dfc17ac31"}},"e890c465960d421a8055a147cbac69e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ecbddb35d994a5897f5dc2fb77c890e","IPY_MODEL_67176fb7130c4979852468ad8236eac1","IPY_MODEL_892a9f8089ab4353982bcab4d1b3f163"],"layout":"IPY_MODEL_ceab9c8497cb45918beb314d06a65b52"}},"ed5a4337e1154020a9d2201da1b47b0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bf90828dddd44118b87f968159f9389","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3105652673c2446abaad8c4fb4cead21","value":231508}},"edeea8866f924c478ca17381f8701963":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efe4b861a2fb4b6d9bb1cd3c711227cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3fa3f1462c740eaa26389fedcad9cd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f56ac4c077e247968d26019137c9b312":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
